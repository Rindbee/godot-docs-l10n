#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Godot Engine 4.5\n"
"Report-Msgid-Bugs-To: \n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_TW\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

msgid "OpenXR hand tracking"
msgstr "OpenXR 手部追蹤"

msgid "Introduction"
msgstr "前言"

msgid ""
"This page focuses specifically on the feature set exposed through OpenXR. "
"Parts of the functionality presented here also applies to WebXR and can by "
"provided by other XR interfaces."
msgstr ""
"本頁重點說明 OpenXR 所提供的手部追蹤功能，部分介紹的功能同樣適用於 WebXR，或"
"可由其他 XR 介面提供。"

msgid ""
"When discussing hand tracking it is important to know that there are "
"differences of opinion as to where lines are drawn. The practical result of "
"this is that there are differences in implementation between the different "
"OpenXR runtimes. You may find yourself in a place where chosen hardware "
"doesn't support a piece of the puzzle or does things differently enough from "
"the other platforms that you need to do extra work."
msgstr ""
"在討論手部追蹤時，需注意各平台對於功能範圍界定有所不同。這導致不同 OpenXR 執"
"行環境在實作上會有差異。你可能會遇到某些硬體不支援特定功能，或其實作方式與其"
"他平台不同，因此需額外處理相容性問題。"

msgid ""
"That said, recent improvements to the OpenXR specification are closing these "
"gaps and as platforms implement these improvements we are getting closer to "
"a future where we have either full portability between platforms or at least "
"a clear way to detect the capabilities of a platform."
msgstr ""
"不過，OpenXR 規範近期已有顯著進步，正逐步縮小這些差異。隨著各平台陸續實作這些"
"改進，未來將更容易實現跨平台相容，或至少能明確偵測平台支援的功能。"

msgid ""
"When we look at the early days of VR the focus of the major platforms was on "
"tracked controller based input. Here we are tracking a physical device that "
"also has buttons for further input. From the tracking data we can infer the "
"location of the player's hands but no further information is known, "
"traditionally it was left up to the game to implement a mechanism to display "
"the player's hand and animate the fingers based on further input from the "
"controller, be it due to buttons being pressed or through proximity sensors. "
"Often fingers are also placed based on context, what the user is holding, "
"and what action a user is performing."
msgstr ""
"回顧 VR 初期，各大平台主要著重於追蹤控制器輸入。此時追蹤的是一個實體裝置，並"
"可藉由按鈕等進行額外輸入。雖可藉由追蹤資料推算玩家手部位置，但無法獲得更多細"
"節，通常需由遊戲自行實作手部顯示及手指動畫，根據控制器按鈕或接近感應器等輸入"
"來決定手指動作。手指的動作也常依情境調整，例如玩家手上拿著什麼、目前正在執行"
"什麼動作等。"

msgid ""
"More recently optical hand tracking has become a popular solution, where "
"cameras track the user's hands and full tracking data for the hand and "
"finger positions becomes available. Many vendors saw this as completely "
"separate from controller tracking and introduced independent APIs to access "
"hand and finger positions and orientation data. When handling input, it was "
"up to the game developer to implement a gesture detection mechanism."
msgstr ""
"近年來，光學手部追蹤成為主流解決方案，利用攝影機偵測使用者雙手，取得完整的手"
"部與手指位置資料。許多廠商視此與控制器追蹤完全獨立，並提供專用 API 以讀取手部"
"與手指的位置及朝向。至於輸入辨識，則通常由遊戲開發者自行實作手勢偵測機制。"

msgid ""
"This split also exists in OpenXR, where controller tracking is handled "
"primarily by the action map system, while optical hand tracking is primarily "
"handled by the hand tracking API extension."
msgstr ""
"這種區分在 OpenXR 中也存在：控制器追蹤主要透過動作對應（Action Map）系統處"
"理，而光學手部追蹤則主要透過手部追蹤 API 擴充來實現。"

msgid ""
"However, the world is not that black and white and we're seeing a number of "
"scenarios where we cross the line:"
msgstr "然而，實務上情況並非如此二分化，實際上有許多情境會跨越這條界線："

msgid ""
"Devices that fit in both categories, such as tracked gloves and controllers "
"such as the Index controller that also perform finger tracking."
msgstr ""
"有些裝置同時屬於兩者，例如具備手指追蹤功能的手套或像 Index 控制器這類可追蹤手"
"指的控制器。"

msgid ""
"XR Runtimes that implement inferred hand tracking from controller data as a "
"means to solve proper finger placement for multiple controllers."
msgstr ""
"某些 XR 執行環境會根據控制器數據推算手部位置，以解決多控制器下的手指擺放問"
"題。"

msgid ""
"XR applications that wish to seamlessly switch between controller and hand "
"tracking offering the same user experience regardless of approach used."
msgstr ""
"一些 XR 應用則希望能無縫切換控制器與手部追蹤，讓使用者不論採用哪種方式都能有"
"一致體驗。"

msgid ""
"OpenXR is answering this call by introducing further extensions that lets us "
"query the capabilities of the XR runtime/hardware or that add further "
"functionality across this divide. The problem that currently does remain is "
"that there are gaps in adopting these extensions, with some platforms thus "
"not reporting capabilities to their full extent. As such you may need to "
"test for the features available on specific hardware and adjust your "
"approach accordingly."
msgstr ""
"OpenXR 也正透過新增各種擴充功能來回應這些需求，讓我們能查詢 XR 執行環境／硬體"
"的功能支援，或跨越傳統分野提供更多功能。不過，這些擴充尚未被所有平台廣泛支"
"援，因此部分平台可能無法完整回報功能能力。開發時必須針對不同硬體測試實際支援"
"狀態，並調整對應策略。"

msgid "Demo project"
msgstr "展示專案"

msgid ""
"The information presented on this page was used to create a demo project "
"that can be found `here <https://github.com/godotengine/godot-demo-projects/"
"tree/master/xr/openxr_hand_tracking_demo>`_."
msgstr ""
"本頁所介紹的內容已用於建置一份展示專案，專案可於此處取得：`https://"
"github.com/godotengine/godot-demo-projects/tree/master/xr/"
"openxr_hand_tracking_demo <https://github.com/godotengine/godot-demo-"
"projects/tree/master/xr/openxr_hand_tracking_demo>`_ 。"

msgid "The Hand Tracking API"
msgstr "手部追蹤 API"

msgid ""
"As mentioned in our introduction, the hand tracking API is primarily used "
"with optical hand tracking and on many platforms only works when the user is "
"not holding a controller. Some platforms support controller inferred hand "
"tracking meaning that you will get hand tracking data even if the user is "
"holding a controller. This includes SteamVR, Meta Quest (currently native "
"only but Meta link support is likely coming), and hopefully soon others as "
"well."
msgstr ""
"如前述，手部追蹤 API 主要用於光學手部追蹤，且多數平台僅於使用者未持控制器時可"
"用。部分平台則支援從控制器數據推算手部追蹤，因此即使玩家手持控制器也能取得手"
"部追蹤資料。目前支援的有 SteamVR、Meta Quest（目前僅原生支援，Meta Link 預計"
"未來也會支援），其他平台也預期陸續支援。"

msgid ""
"The hand tracking implementation in Godot has been standardized around the "
"Godot Humanoid Skeleton and works both in OpenXR and WebXR. The instructions "
"below will thus work in both environments."
msgstr ""
"Godot 的手部追蹤功能已標準化，採用 Godot Humanoid Skeleton（人形骨架），可同"
"時用於 OpenXR 與 WebXR。以下說明皆適用於這兩種環境。"

msgid ""
"In order to use the hand tracking API with OpenXR you first need to enable "
"it. This can be done in the project settings:"
msgstr "在 OpenXR 環境使用手部追蹤 API 前，需先於專案設定中啟用相關功能："

msgid ""
"For some standalone XR devices you also need to configure the hand tracking "
"extension in export settings, for instance for Meta Quest:"
msgstr ""
"某些獨立式 XR 裝置（如 Meta Quest）還需於匯出設定中啟用手部追蹤擴充功能："

msgid "Now you need to add 3 components into your scene for each hand:"
msgstr "接著，請在場景中為每隻手分別加入以下三個元件："

msgid "A tracked node to position the hand."
msgstr "一個用於定位手部的追蹤節點。"

msgid "A properly skinned hand mesh with skeleton."
msgstr "一個綁定好骨架與蒙皮的手部網格（Mesh）。"

msgid "A skeleton modifier that applies finger tracking data to the skeleton."
msgstr "一個骨架修改器，用於將手指追蹤資料套用至骨架。"

msgid "Hand tracking node"
msgstr "手部追蹤節點"

msgid ""
"The hand tracking system uses separate hand trackers to track the position "
"of the player's hands within our tracking space."
msgstr ""
"手部追蹤系統會針對玩家雙手分別建立追蹤器，在追蹤空間中即時追蹤手部位置。"

msgid "This information has been separated out for the following use cases:"
msgstr "這項設計主要針對下列情境進行區分："

msgid ""
"Tracking happens in the local space of the :ref:`XROrigin3D "
"<class_xrorigin3d>` node. This node must be a child of the `XROrigin3D` node "
"in order to be correctly placed."
msgstr ""
"追蹤會在 :ref:`XROrigin3D <class_xrorigin3d>` 節點的本地座標空間進行。必須將"
"手部追蹤節點設為 `XROrigin3D` 的子節點，才能正確定位。"

msgid ""
"This node can be used as an IK target when an upper body mesh with arms is "
"used instead of separate hand meshes."
msgstr ""
"當你使用帶有手臂的上半身網格（而非單獨的手部網格）時，也可以將手部追蹤節點作"
"為 IK（反向運動學）的目標節點。"

msgid ""
"Actual placement of the hands may be loosely bound to the tracking in "
"scenarios such as avatar creation UIs, fake mirrors, or similar situations "
"resulting in the hand mesh and finger tracking being localized elsewhere."
msgstr ""
"在某些情境下（如虛擬人偶創建 UI、鏡像效果等），手部的實際顯示位置可能不會嚴格"
"綁定追蹤資料，因而手部網格與手指追蹤可能會被定位到其他位置。"

msgid "We'll concentrate on the first use case only."
msgstr "以下將僅聚焦於第一種使用情境。"

msgid ""
"For this you need to add an :ref:`XRNode3D <class_xrnode3d>` node to your "
"``XROrigin3D`` node."
msgstr ""
"你需要在 ``XROrigin3D`` 節點下新增一個 :ref:`XRNode3D <class_xrnode3d>` 節"
"點。"

msgid ""
"On this node the ``tracker`` should be set to ``/user/hand_tracker/left`` or "
"``/user/hand_tracker/right`` for the left or right hand respectively."
msgstr ""
"在該節點上，將 ``tracker`` 設為 ``/user/hand_tracker/left`` 或 ``/user/"
"hand_tracker/right``，分別對應左手或右手。"

msgid ""
"The ``pose`` should remain set to ``default``, no other option will work "
"here."
msgstr "``pose`` 屬性需保持 ``default``，其他選項無法正常運作。"

msgid ""
"The checkbox ``Show When Tracked`` will automatically hide this node if no "
"tracking data is available, or make this node visible if tracking data is "
"available."
msgstr ""
"勾選 ``Show When Tracked`` （有追蹤時顯示）時，若無追蹤資料則自動隱藏節點，有"
"追蹤資料時則顯示。"

msgid "Rigged hand mesh"
msgstr "綁定骨架的手部網格"

msgid ""
"In order to display our hand we need a hand mesh that is properly rigged and "
"skinned. For this Godot uses the hand bone structure as defined for "
"the :ref:`Godot Humanoid <class_skeletonprofilehumanoid>` but optionally "
"supporting an extra tip bone for each finger."
msgstr ""
"要顯示手部模型，需要一個綁定好骨架與蒙皮的手部網格。Godot 採用 :ref:`Godot "
"Humanoid <class_skeletonprofilehumanoid>` 定義的手部骨架結構，每根手指也可額"
"外加入指尖骨骼。"

msgid ""
"The `OpenXR hand tracking demo <https://github.com/godotengine/godot-demo-"
"projects/tree/master/xr/openxr_hand_tracking_demo>`_ contains example glTF "
"files of properly rigged hands."
msgstr ""
"`OpenXR 手部追蹤展示專案 <https://github.com/godotengine/godot-demo-projects/"
"tree/master/xr/openxr_hand_tracking_demo>`_ 中包含已正確綁定骨架的 glTF 手部"
"範例檔案。"

msgid ""
"We will be using those here and add them as a child to our ``XRNode3D`` "
"node. We also need to enable editable children to gain access to "
"our :ref:`Skeleton3D <class_skeleton3d>` node."
msgstr ""
"以下將以這些範例檔案為例，並將其作為 ``XRNode3D`` 的子節點。你也需要啟用可編"
"輯子節點，以便存取 :ref:`Skeleton3D <class_skeleton3d>` 節點。"

msgid "The hand skeleton modifier"
msgstr "手部骨架修改器"

msgid ""
"You need to set the ``Hand Tracker`` property to either ``/user/hand_tracker/"
"left`` or ``/user/hand_tracker/right`` depending on whether we are apply the "
"tracking data of respectively the left or right hand."
msgstr ""
"請將 ``Hand Tracker`` 屬性設為 ``/user/hand_tracker/left`` 或 ``/user/"
"hand_tracker/right``，分別對應左手或右手。"

msgid "You can also set the ``Bone Update`` mode on this node."
msgstr "你也可以設定此節點的 ``Bone Update`` （骨骼更新）模式。"

msgid ""
"``Full`` applies the hand tracking data fully. This does mean that the "
"skeleton positioning will potentially reflect the size of the actual hand of "
"the user. This can lead to scrunching effect if meshes aren't weighted "
"properly to account for this. Make sure you test your game with players of "
"all sizes when optical hand tracking is used!"
msgstr ""
"選擇 ``Full`` （完整）模式時，會完整套用手部追蹤資料，骨架位置將反映實際使用"
"者的手部尺寸。如果網格權重設置不當，可能會出現模型擠壓的現象。使用光學手部追"
"蹤時，請務必用各種不同手型多做測試！"

msgid ""
"``Rotation Only`` will only apply rotation to the bones of the hands and "
"keep the bone length as is. In this mode the size of the hand mesh doesn't "
"change."
msgstr ""
"選擇 ``Rotation Only`` （僅旋轉）時，只會將手部骨骼旋轉套用至骨架，骨骼長度不"
"變，手部網格大小也不會改變。"

msgid ""
"With this added, when we run the project we should see the hand correctly "
"displayed if hand tracking is supported."
msgstr "完成上述設置後，執行專案時若支援手部追蹤，應可正確顯示手部模型。"

msgid "The hand tracking data source"
msgstr "手部追蹤資料來源"

msgid ""
"This is an OpenXR extension that provides information about the source of "
"the hand tracking data. At this moment only a few runtimes implement it but "
"if it is available, Godot will activate it."
msgstr ""
"這是一個 OpenXR 擴充功能，可提供手部追蹤資料來源的資訊。目前僅少數執行環境實"
"作此功能，但只要有支援，Godot 會自動啟用。"

msgid ""
"If this extension is not supported and thus unknown is returned, you can "
"make the following assumptions:"
msgstr "若此擴充功能不被支援（回傳 unknown），可依下列假設推斷："

msgid ""
"If you are using SteamVR (including Steam link), only controller based hand "
"tracking is supported."
msgstr "若使用 SteamVR（含 Steam Link），僅支援以控制器為基礎的手部追蹤。"

msgid ""
"For any other runtime, if hand tracking is supported, only optical hand "
"tracking is supported (Note, Meta Link currently fall into this category)."
msgstr ""
"其他執行環境若支援手部追蹤，則僅支援光學手部追蹤 （註：Meta Link 目前也屬此"
"類）。"

msgid "In all other cases, no hand tracking is supported at all."
msgstr "其餘情況皆不支援手部追蹤。"

msgid "You can access this information through code:"
msgstr "你可以透過程式碼存取這項資訊："

msgid "This example logs the state for the left hand."
msgstr "此範例會記錄左手的追蹤狀態。"

msgid ""
"If in this example no hand tracker is returned by ``get_tracker``, this "
"means the hand tracking API is not supported on the XR runtime at all."
msgstr ""
"若 ``get_tracker`` 未回傳任何手部追蹤器，表示該 XR 執行環境完全不支援手部追"
"蹤 API。"

msgid ""
"If there is a tracker but `has_tracking_data` is false, the user's hand is "
"currently not being tracked. This is likely caused by one of the following "
"reasons:"
msgstr ""
"若有追蹤器但 `has_tracking_data` 為 false，表示目前使用者的手未被追蹤。常見原"
"因如下："

msgid ""
"The player's hand is not visible by any of the tracking cameras on the "
"headset"
msgstr "玩家的手未被頭戴裝置上的任何追蹤攝影機偵測到"

msgid ""
"The player is currently using a controller and the headset only supports "
"optical hand tracking"
msgstr "玩家正在使用控制器，且頭戴裝置僅支援光學手部追蹤"

msgid ""
"The controller is turned off and only controller hand tracking is supported."
msgstr "控制器已關閉，且僅支援控制器手部追蹤。"

msgid "Handling user input"
msgstr "處理使用者輸入"

msgid ""
"Reacting to actions performed by the user is handled "
"through :ref:`doc_xr_action_map` if controllers are used. In the action map "
"you can map various inputs like the trigger or joystick on the controller to "
"an action. This can then drive logic in your game."
msgstr ""
"若使用控制器，建議透過 :ref:`doc_xr_action_map` 處理使用者動作。在動作對應表"
"中，可將控制器的扳機鍵、搖桿等輸入對應到特定動作，再據此驅動遊戲邏輯。"

msgid ""
"When hand tracking is used we originally had no such inputs, inputs are "
"driven by gestures made by the user such as making a fist to grab or "
"pinching the thumb and index finger together to select something. It was up "
"to the game developer to implement this."
msgstr ""
"早期使用手部追蹤時並無對應的輸入，必須透過使用者手勢（如握拳表抓取、拇指與食"
"指捏合表選取等）來操作。這部分通常需由開發者自行實作。"

msgid ""
"Recognizing that there is an increasing demand for applications that can "
"switch seamlessly between controller and hand tracking and the need some "
"form of basic input capability, a number of extensions were added to the "
"specification that provide some basic gesture recognition and can be used "
"with the action map."
msgstr ""
"隨著越來越多應用需要在控制器與手部追蹤間無縫切換，且需具備基本輸入能力，"
"OpenXR 規範新增了多項擴充，提供基本手勢辨識，可與動作對應表（Action Map）結合"
"使用。"

msgid "The hand interaction profile"
msgstr "手部互動設定檔"

msgid ""
"The `hand interaction profile extension <https://github.khronos.org/OpenXR-"
"Inventory/extension_support.html#XR_EXT_hand_interaction>`_ is a new core "
"extension which supports pinch, grasp, and poke gestures and related poses. "
"There is still limited support for this extension but it should become "
"available in more runtimes in the near future."
msgstr ""
"`手部互動設定檔擴充 <https://github.khronos.org/OpenXR-Inventory/"
"extension_support.html#XR_EXT_hand_interaction>`_ 為全新核心擴充，支援捏合"
"（Pinch）、抓握（Grasp）、點按（Poke）等手勢及相關姿勢。目前僅有部分執行環境"
"支援，未來預計會有更多平台支援。"

msgid ""
"The pinch gesture is triggered by pinching your thumb and index finger "
"together. This is often used as a select gesture for menu systems, similar "
"to using your controller to point at an object and press the trigger to "
"select and is thus often mapped as such."
msgstr ""
"捏合手勢（Pinch）是指拇指與食指捏在一起，常用於選取動作（如選單選擇），類似以"
"控制器指向物件並按下扳機選取，通常也會這樣對應。"

msgid ""
"The ``pinch pose`` is a pose positioned in the middle between the tip of the "
"thumb and the tip of the index finger and oriented such that a ray cast can "
"be used to identify a target."
msgstr ""
"``pinch pose`` （捏合姿勢）會定位在拇指與食指指尖的中間，並以適合進行射線檢測"
"的方向排列，以便偵測選取目標。"

msgid ""
"The ``pinch`` float input is a value between 0.0 (the tip of the thumb and "
"index finger are apart) and 1.0 (the tip of the thumb and index finger are "
"touching)."
msgstr ""
"``pinch`` （捏合）輸入為浮點數，0.0 代表拇指與食指分開，1.0 代表指尖接觸。"

msgid ""
"The ``pinch ready`` input is true when the tips of the fingers are (close "
"to) touching."
msgstr "``pinch ready`` （捏合就緒）輸入在指尖接觸（或非常接近）時為 true。"

msgid ""
"The grasp gesture is triggered by making a fist and is often used to pick "
"items up, similar to engaging the squeeze input on controllers."
msgstr ""
"抓握手勢（Grasp）為握拳動作，常用於拾取物品，與控制器上的壓握（Squeeze）輸入"
"類似。"

msgid ""
"The ``grasp`` float input is a value between 0.0 (open hand) and 1.0 (fist)."
msgstr "``grasp`` （抓握）輸入為浮點數，0.0 代表手掌張開，1.0 代表握拳。"

msgid "The ``grasp ready`` input is true when the user made a fist."
msgstr "``grasp ready`` （抓握就緒）輸入在使用者握拳時為 true。"

msgid ""
"The poke gesture is triggered by extending your index finger, this one is a "
"bit of an exception as the pose at the tip of your index finger is often "
"used to poke an interactable object. The ``poke pose`` is a pose positioned "
"on the tip of the index finger."
msgstr ""
"點按手勢（Poke）是將食指伸直，常用於點擊可互動物件。 ``poke pose`` （點按姿"
"勢）會定位於食指指尖。"

msgid ""
"Finally the ``aim activate (ready)`` input is defined as an input that is "
"1.0/true when the index finger is extended and pointing at a target that can "
"be activated. How runtimes interpret this, is not clear."
msgstr ""
"最後，``aim activate (ready)`` 輸入在食指伸直並指向可啟動目標時會為 1.0/"
"true，不過不同執行環境可能解讀方式略有差異。"

msgid ""
"With this setup the normal ``left_hand`` and ``right_hand`` trackers are "
"used and you can thus seamlessly switch between controller and hand tracking "
"input."
msgstr ""
"完成上述設定後，會使用標準的 ``left_hand`` 與 ``right_hand`` 追蹤器，因此可在"
"控制器與手部追蹤間無縫切換輸入方式。"

msgid ""
"You need to enable the hand interaction profile extension in the OpenXR "
"project settings."
msgstr "你需要在 OpenXR 專案設定中啟用手部互動設定檔擴充功能。"

msgid "Microsoft hand interaction profile"
msgstr "Microsoft 手部互動設定檔"

msgid ""
"The `Microsoft hand interaction profile extension <https://"
"github.khronos.org/OpenXR-Inventory/"
"extension_support.html#XR_MSFT_hand_interaction>`_ was introduced by "
"Microsoft and loosely mimics the simple controller profile. Meta has also "
"added support for this extension but only on their native OpenXR client, it "
"is currently not available over Meta Link."
msgstr ""
"`Microsoft 手部互動設定檔擴充 <https://github.khronos.org/OpenXR-Inventory/"
"extension_support.html#XR_MSFT_hand_interaction>`_ 由微軟提出，設計上大致模仿"
"簡易控制器設定檔。Meta 也已支援此擴充，但僅限其原生 OpenXR 用戶端，目前在 "
"Meta Link 上尚未提供。"

msgid ""
"Pinch support is exposed through the ``select`` input, the value of which is "
"0.0 when the tip of the thumb and index finger are apart and 1.0 when they "
"are together."
msgstr ""
"捏合動作可透過 ``select`` 輸入取得：拇指與食指分開時值為 0.0，指尖接觸時為 "
"1.0。"

msgid ""
"Note that in this profile the ``aim pose`` is redefined as a pose between "
"thumb and index finger, oriented so a ray cast can be used to identify a "
"target."
msgstr ""
"注意，此設定檔中 ``aim pose`` （瞄準姿勢）重新定義為拇指與食指之間的位置，並"
"以便於進行射線檢測的方向排列。"

msgid ""
"Grasp support is exposed through the ``squeeze`` input, the value of which "
"is 0.0 when the hand is open, and 1.0 when a fist is made."
msgstr ""
"抓握動作可透過 ``squeeze`` 輸入取得：手掌張開時值為 0.0，握拳時為 1.0。"

msgid "HTC hand interaction profile"
msgstr "HTC 手部互動設定檔"

msgid ""
"The `HTC hand interaction profile extension <https://github.khronos.org/"
"OpenXR-Inventory/extension_support.html#XR_HTC_hand_interaction>`_ was "
"introduced by HTC and is defined similarly to the Microsoft extension. It is "
"only supported by HTC for the Focus 3 and Elite XR headsets."
msgstr ""
"`HTC 手部互動設定檔擴充 <https://github.khronos.org/OpenXR-Inventory/"
"extension_support.html#XR_HTC_hand_interaction>`_ 由 HTC 提出，定義方式與 "
"Microsoft 擴充類似。目前僅 HTC Focus 3 與 Elite XR 頭顯支援。"

msgid "See the Microsoft hand interaction profile for the gesture support."
msgstr "手勢支援請參考 Microsoft 手部互動設定檔。"

msgid ""
"The defining difference is that this extension introduces two new trackers, "
"``/user/hand_htc/left`` and ``/user/hand_htc/right``. This means that extra "
"logic needs to be implemented to switch between the default trackers and the "
"HTC specific trackers when the user puts down, or picks up, their controller."
msgstr ""
"主要差異在於，該擴充額外引入 ``/user/hand_htc/left`` 與 ``/user/hand_htc/"
"right`` 兩個追蹤器。當使用者放下或拿起控制器時，需額外撰寫邏輯在預設追蹤器與 "
"HTC 專屬追蹤器間切換。"

msgid "Simple controller profile"
msgstr "簡易控制器設定檔"

msgid ""
"The simple controller profile is a standard core profile defined as a "
"fallback profile when a controller is used for which no profile exists."
msgstr "簡易控制器設定檔是標準核心設定檔，作為無專屬設定檔之控制器的備援方案。"

msgid ""
"There are a number of OpenXR runtimes that will mimic controllers through "
"the simple controller profile when hand tracking is used."
msgstr "有些 OpenXR 執行環境會在手部追蹤時模擬成簡易控制器設定檔。"

msgid ""
"Unfortunately there is no sound way to determine whether an unknown "
"controller is used or whether hand tracking is emulating a controller "
"through this profile."
msgstr ""
"遺憾的是，目前無法可靠區分究竟是未知控制器，還是手部追蹤透過此設定檔模擬為控"
"制器。"

msgid ""
"XR runtimes are free to define how the simple controller profile operates, "
"so there is also no certainty to how this profile is mapped to gestures."
msgstr ""
"各 XR 執行環境可自行定義簡易控制器設定檔的行為，因此手勢對應方式也不盡相同，"
"無法統一保證。"

msgid ""
"The most common mapping seems to be that ``select click`` is true when the "
"tip of the thumb and index fingers are touching while the user's palm is "
"facing away from the user. ``menu click`` will be true when tip of the thumb "
"and index fingers are touching while the user's palm is facing towards the "
"user."
msgstr ""
"最常見的對應方式為：當拇指與食指指尖接觸且手掌朝外時， ``select click`` （選"
"取點擊）為 true；手掌朝內時， ``menu click`` （選單點擊）為 true。"

msgid ""
"As some of these interaction profiles have overlap it is important to know "
"that you can add each profile to your action map and the XR runtime will "
"choose the best fitting profile."
msgstr ""
"由於這些互動設定檔部分功能重疊，你可以將多個設定檔加入動作對應表，XR 執行環境"
"會自動選取最合適的設定檔。"

msgid ""
"For instance, a Meta Quest supports both the Microsoft hand interaction "
"profile and simple controller profile. If both are specified the Microsoft "
"hand interaction profile will take precedence and will be used."
msgstr ""
"例如，Meta Quest 同時支援 Microsoft 手部互動設定檔與簡易控制器設定檔，若兩者"
"皆指定，則會優先使用 Microsoft 設定檔。"

msgid ""
"The expectation is that once Meta supports the core hand interaction profile "
"extension, that profile will take precedence over both Microsoft and simple "
"controller profiles."
msgstr ""
"預期未來 Meta 一旦支援核心手部互動設定檔擴充，將會優先於 Microsoft 與簡易控制"
"器設定檔。"

msgid "Gesture based input"
msgstr "基於手勢的輸入"

msgid ""
"If the platform doesn't support any interaction profiles when hand tracking "
"is used, or if you're building an application where you need more "
"complicated gesture support you're going to need to build your own gesture "
"recognition system."
msgstr ""
"若平台在手部追蹤時不支援任何互動設定檔，或你需要更複雜的手勢支援，則需自行實"
"作手勢辨識系統。"

msgid ""
"You can obtain the full hand tracking data through the :ref:`XRHandTracker "
"<class_xrhandtracker>` resource for each hand. You can obtain the hand "
"tracker by calling ``XRServer.get_tracker`` and using either ``/user/"
"hand_tracker/left`` or ``/user/hand_tracker/left`` as the tracker. This "
"resource provides access to all the joint information for the given hand."
msgstr ""
"你可以透過每隻手的 :ref:`XRHandTracker <class_xrhandtracker>` 資源取得完整手"
"部追蹤資料。可呼叫 ``XRServer.get_tracker`` 並以 ``/user/hand_tracker/left`` "
"或 ``/user/hand_tracker/right`` 做為追蹤器名稱，取得對應手部追蹤器。這個資源"
"可存取該手所有關節資訊。"

msgid ""
"Detailing out a full gesture recognition algorithm goes beyond the scope of "
"this manual however there are a number of community projects you can look at:"
msgstr "完整的手勢辨識演算法超出本手冊範疇，不過你可以參考下列社群專案："

msgid ""
"`Julian Todd's Auto hands library <https://github.com/Godot-Dojo/Godot-XR-"
"AH>`_"
msgstr ""
"`Julian Todd 的 Auto hands 函式庫 <https://github.com/Godot-Dojo/Godot-XR-"
"AH>`_"

msgid ""
"`Malcolm Nixons Hand Pose Detector <https://github.com/Malcolmnixon/"
"GodotXRHandPoseDetector>`_"
msgstr ""
"`Malcolm Nixon 的 Hand Pose Detector <https://github.com/Malcolmnixon/"
"GodotXRHandPoseDetector>`_"
